{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cbeeb94-fc04-4676-bf9d-4f402b7f864e",
   "metadata": {},
   "source": [
    "# Convert MONAI models to OpenVINO\n",
    "\n",
    "This notebook loads MONAI models listed on https://docs.monai.io/en/latest/networks.html#nets and converts them to ONNX and IR. Models list is current as of November 11, 2021 with MONAI 0.7.0\n",
    "\n",
    "This notebook converts all listed models except:\n",
    "- SENet: SENet architecture is validated by converting SENet154 instead of the generic SENet model\n",
    "- Tranchex: Tranchex has a multimodal architecture that requires specific arguments. Tranchex has been manually validated and code will be added soon\n",
    "- Netadapter: This is not a model, but a wrapper to replace a layer with a PyTorch model layer\n",
    "- VitAutoEnc: does not exist in Monai 0.7.0\n",
    "- TorchVisionFullyConvModel: deprecated (according to MONAI docs) in favor of TorchVisionFCModel\n",
    "\n",
    "Running the notebook requires installing monai, openvino-dev and a few other dependencies. Executing the next cell installs these packages in the current Python/Jupyter environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094cfd4d-35b9-4e4b-9b44-b417bd4e13b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade monai openvino-dev torch torchvision onnx einops ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5d50d-acad-44d7-a7b2-5d5138c6fe8c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db1c72-8d54-4192-8ffa-ee2ebab67c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import monai.networks.nets as nets\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import Markdown\n",
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547a8b8f-108d-46e3-8e45-4f186f81c256",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Set `ONNX_DIR` and `IR_DIR` to the names of the directories where the converted ONNX and IR models should be saved. These directories will be created if they do not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e2f2f-20f3-4408-88a8-d5aac6fb22b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_DIR = \"onnx_models\"\n",
    "IR_DIR = \"ir_models\"\n",
    "\n",
    "Path(ONNX_DIR).mkdir(exist_ok=True)\n",
    "Path(IR_DIR).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffdec9c-0606-4b1d-9e12-8cb5083c4c56",
   "metadata": {},
   "source": [
    "`default_args` defines default argument for models, `network_args` overrides some default arguments for specific networks. Network dimensions are by default set to `1, in_channels, 128,128,128` for 3D networks and `1, in_channels, 128,128` for 2D networks. Some networks need a specific input shape, which is defined in `network_dims`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8528db-4db5-4750-9e45-5aef06b037fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These values work - but will likely not result in a good model\n",
    "# For testing purposes only\n",
    "\n",
    "default_args = {\n",
    "    \"channels\": [2, 2],\n",
    "    \"depth\": 5,\n",
    "    \"img_size\": 128,\n",
    "    \"in_channels\": 1,\n",
    "    \"in_shape\": (1, 128, 128),\n",
    "    \"model_name\": \"efficientnet-b0\",\n",
    "    \"num_channel_initial\": 16,\n",
    "    \"out_channels\": 1,\n",
    "    \"spatial_dims\": 2,\n",
    "    \"strides\": ((1, 2), 1, 1),\n",
    "}\n",
    "\n",
    "network_args = {\n",
    "    \"AutoEncoder\": {\"strides\": [1, 1]},\n",
    "    \"Classifier\": {\"classes\": 2},\n",
    "    \"DynUNet\": {\"kernel_size\": ((1, 2), 1, 1), \"upsample_kernel_size\": (1, 1)},\n",
    "    \"EfficientNet\": {\"blocks_args_str\": [\"r1_k3_s11_e1_i32_o16_se0.25\"]},\n",
    "    \"FullyConnectedNet\": {\"in_channels\": 16384, \"hidden_channels\": []},\n",
    "    \"Generator\": {\"start_shape\": (64, 8, 8), \"latent_shape\": (128, 128)},\n",
    "    \"GlobalNet\": {\"image_size\": (128, 128)},\n",
    "    \"LocalNet\": {\"extract_levels\": [1]},\n",
    "    \"Regressor\": {\"out_shape\": (128, 128)},\n",
    "    \"SegResNetVAE\": {\"input_image_size\": [1, 128, 128]},\n",
    "    \"TorchVisionFCModel\": {\"pool\": None},\n",
    "    \"UNETR\": {\"spatial_dims\": 2},\n",
    "    \"VarAutoEncoder\": {\"strides\": [1, 1], \"latent_size\": 2},\n",
    "    \"ViT\": {\"img_size\": (1, 128, 128), \"patch_size\": (1, 16, 16)},\n",
    "}\n",
    "\n",
    "network_dims = {\n",
    "    \"FullyConnectedNet\": [1, 128 * 128],\n",
    "    \"Generator\": (1, 1, 1, 128, 128),\n",
    "    \"HighResNet\": (1, 1, 64, 64, 64),\n",
    "    \"Regressor\": (1, 1, 128, 128),\n",
    "    \"TorchVisionFCModel\": (1, 3, 256, 256),\n",
    "    \"UNETR\": (1, 1, 128, 128),\n",
    "    \"ViT\": (1, 1, 1, 128, 128),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f8ef5-c222-401a-95da-1b5d53bfa7b9",
   "metadata": {},
   "source": [
    "`monai_net_names` is a string of models ot convert, separated by spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f190c020-d318-49c9-8418-fdff15f8e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "monai_net_names = \"AHNet DenseNet DenseNet121 DenseNet169 DenseNet201 DenseNet264 EfficientNet EfficientNetBN EfficientNetBNFeatures SegResNet SegResNetVAE SENet154 SEResNet50 SEResNet101 SEResNet152 SEResNext50 SEResNext101 HighResNet DynUNet UNet UNETR BasicUNet VNet RegUNet GlobalNet LocalNet AutoEncoder VarAutoEncoder ViT FullyConnectedNet Generator Regressor Classifier Discriminator Critic TorchVisionFCModel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd25c14-266d-41b4-bb36-93676136c8e2",
   "metadata": {},
   "source": [
    "## Convert to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465ef45-a169-440f-a0ff-7f3c172ae758",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "logging.basicConfig(filename=\"monai_models.log\", level=logging.INFO)\n",
    "monai_nets = monai_net_names.split(\" \")\n",
    "monai_nets = [net_name.strip() for net_name in monai_nets]\n",
    "num = len(monai_nets)\n",
    "\n",
    "for i, net_name in enumerate(sorted(monai_nets)):\n",
    "    print(f\"[{i+1}/{num}] {net_name}\", end=\" \")\n",
    "    net = getattr(nets, net_name)\n",
    "    kwargs = {}\n",
    "    # Override default arguments if necessary\n",
    "    if net_name in network_args:\n",
    "        for key, value in network_args[net_name].items():\n",
    "            kwargs[key] = value\n",
    "\n",
    "    # Find parameters to use with this network\n",
    "    argset = set()\n",
    "    for arg in inspect.signature(net).parameters.values():\n",
    "        if arg.name == \"pool\":\n",
    "            argset.add(arg.name)\n",
    "        elif arg.default == inspect._empty and arg.name not in [\"args\", \"kwargs\"]:\n",
    "            argset.add(arg.name)\n",
    "\n",
    "    # Some networks require default arguments only defined in a parent class\n",
    "    for arg in inspect.signature(net.__bases__[0]).parameters.values():\n",
    "        if (\n",
    "            arg.default == inspect._empty\n",
    "            and arg.name not in [\"args\", \"kwargs\"]\n",
    "            and arg.name not in inspect.signature(net).parameters\n",
    "            and arg.name in {\"in_channels\", \"out_channels\", \"spatial_dims\"}\n",
    "        ):\n",
    "            argset.add(arg.name)\n",
    "    kwargs.update({arg: default_args[arg] for arg in argset if arg not in kwargs})\n",
    "\n",
    "    # VarAutoEncoder inherits from AutoEncoder and should support in_channels, but does not.\n",
    "    if net_name == \"VarAutoEncoder\":\n",
    "        kwargs.pop(\"in_channels\")\n",
    "\n",
    "    # Load the MONAI network\n",
    "    try:\n",
    "        monainet = net(**kwargs)\n",
    "    except:\n",
    "        print(\"loading failed\")\n",
    "        raise\n",
    "\n",
    "    # Determine input shape for ONNX export\n",
    "    input_shape = list(list(monainet.parameters())[0].shape)\n",
    "    in_channels = input_shape[1] if len(input_shape) > 3 else input_shape[0]\n",
    "    if net_name in network_dims:\n",
    "        new_input_shape = network_dims[net_name]\n",
    "    elif len(input_shape) == 5:\n",
    "        new_input_shape = (1, in_channels, 128, 128, 128)\n",
    "    elif len(input_shape) == 3 or len(input_shape) == 4:\n",
    "        new_input_shape = (1, in_channels, 128, 128)\n",
    "\n",
    "    # Log the model with the arguments, and input shape\n",
    "    # for example SEResNet50(in_channels=1, spatial_dims=2)\n",
    "    model_args = \", \".join(f\"{key}={value}\" for (key, value) in kwargs.items())\n",
    "    logging.info(rf\"{net_name}({model_args}) input shape: {new_input_shape}\")\n",
    "\n",
    "    # Export to ONNX\n",
    "    dummy_input = torch.randn(new_input_shape)\n",
    "    print(new_input_shape, end=\" \")\n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            monainet,\n",
    "            dummy_input,\n",
    "            f\"{ONNX_DIR}/{net_name}.onnx\",\n",
    "            opset_version=12,\n",
    "            do_constant_folding=False,\n",
    "        )\n",
    "        print(\"succeeded\")\n",
    "    except:\n",
    "        print(\"converting failed\")\n",
    "        raise\n",
    "    finally:\n",
    "        del monainet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a3817-d729-4c9a-9cda-b40f797628c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convert to OpenVINO IR\n",
    "\n",
    "Convert all ONNX models to IR format. Model Optimizer output is not shown in the notebook, but added to mo_log.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7335efef-9112-45fa-ab17-b4dee370e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_models = list(Path(ONNX_DIR).glob(\"*.onnx\"))\n",
    "log = Path(\"mo_log.txt\")\n",
    "num = len(onnx_models)\n",
    "with open(log, mode=\"a\") as logfile:\n",
    "    for i, onnx_model_path in enumerate(onnx_models):\n",
    "        ir_path = Path(IR_DIR) / onnx_model_path.with_suffix(\".xml\").name\n",
    "        if not ir_path.exists():\n",
    "            print(f\"[{i+1}/{num}] Converting {ir_path.stem}...\")\n",
    "            mo_result = !mo --data_type FP16 --input_model $onnx_model_path --output_dir $IR_DIR\n",
    "            logfile.writelines(mo_result.get_nlstr())\n",
    "        else:\n",
    "            print(f\"[{i+1}/{num}] Skipping {ir_path.stem} (already exists)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21604ca4-ead5-4f01-85c2-e5bcd593cf7c",
   "metadata": {},
   "source": [
    "## Verify that all models converted to ONNX and IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c44e8-69a1-4318-b8a7-5687e4e51ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_missing = False\n",
    "\n",
    "for net in monai_nets:\n",
    "    onnx_path=Path(f\"{ONNX_DIR}/{net_name}.onnx\")\n",
    "    if not onnx_path.exists():\n",
    "        print(f\"{onnx_path} does not exist\")\n",
    "        found_missing = True\n",
    "\n",
    "for onnx_model_path in onnx_models:\n",
    "    ir_path = Path(IR_DIR) / onnx_model_path.with_suffix(\".xml\").name\n",
    "    if not ir_path.exists():\n",
    "        print(f\"{ir_path} does not exist\")\n",
    "        found_missing = True\n",
    "        \n",
    "if found_missing:\n",
    "    raise Exception(\"Not all MONAI models converted successfully\")\n",
    "else:\n",
    "    print(\"All MONAI models converted to ONNX and IR!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db6be4-c4cf-487c-b6d5-70b7f2a54013",
   "metadata": {},
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80ca60-72d5-4cfc-a106-f7c7f3570dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude Regressor. With the current network parameters it crashes Jupyter on CPU,\n",
    "# but works fine on GPU\n",
    "ignore_models = [\"Regressor\"]\n",
    "ir_models = Path(IR_DIR).glob(\"*.xml\")\n",
    "for ir_path in ir_models:\n",
    "    if ir_path.stem not in ignore_models:\n",
    "        print(ir_path, end=\" \")\n",
    "        ie = IECore()\n",
    "        net = ie.read_network(model=ir_path)\n",
    "        exec_net = ie.load_network(network=net, device_name=\"CPU\")\n",
    "        input_layer = next(iter(net.input_info))\n",
    "        output_layer = next(iter(net.outputs))\n",
    "\n",
    "        input_dims = net.input_info[input_layer].tensor_desc.dims\n",
    "        print(input_dims, end=\" \")\n",
    "        input_data = np.random.randint(low=0, high=255, size=input_dims, dtype=np.uint8).astype(\n",
    "            np.float32\n",
    "        )\n",
    "        result = exec_net.infer({input_layer: input_data})\n",
    "        print(\"succeeded\" if result.get(output_layer) is not None else \"failed\")\n",
    "        del net\n",
    "        del exec_net\n",
    "        del ie\n",
    "        del input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9aeedc-f1e8-4a88-981e-f57287205559",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Benchmark\n",
    "\n",
    "Benchmark all models. This will take quite a long time, and not give very accurate output. For testing purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10092fcc-b386-4066-921a-01cf13e53d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(model_path: os.PathLike,\n",
    "                    device: str = \"CPU\",\n",
    "                    seconds: int = 60, api: str = \"async\",\n",
    "                    batch: int = 1, \n",
    "                    cache_dir=\"model_cache\"):\n",
    "    ie = IECore()\n",
    "    model_path = Path(model_path)\n",
    "    if (\"GPU\" in device) and (\"GPU\" not in ie.available_devices):\n",
    "        raise ValueError(f\"A GPU device is not available. Available devices are: {ie.available_devices}\")\n",
    "    else:\n",
    "        benchmark_command = f\"benchmark_app -m {model_path} -d {device} -t {seconds} -api {api} -b {batch} -cdir {cache_dir}\"\n",
    "        display(Markdown(f\"**Benchmark {model_path.name} with {device} for {seconds} seconds with {api} inference**\"));\n",
    "        display(Markdown(f\"Benchmark command: `{benchmark_command}`\"));\n",
    "\n",
    "        benchmark_output = %sx $benchmark_command\n",
    "        benchmark_result = [line for line in benchmark_output\n",
    "                            if not (line.startswith(r\"[\") or line.startswith(\"  \") or line == \"\")]\n",
    "        print(\"\\n\".join(benchmark_result))\n",
    "        print()\n",
    "        if \"MULTI\" in device:\n",
    "            devices = device.replace(\"MULTI:\",\"\").split(\",\")\n",
    "            for single_device in devices:\n",
    "                print(f\"{single_device} device: {ie.get_metric(device_name=single_device, metric_name='FULL_DEVICE_NAME')}\")\n",
    "        else:\n",
    "            print(f\"Device: {ie.get_metric(device_name=device, metric_name='FULL_DEVICE_NAME')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d57ecfa-4bcf-47cb-8ea6-cc349b236794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore_models = [\"Regressor\"]\n",
    "# ir_models = Path(IR_DIR).glob(\"*.xml\")\n",
    "# for ir_path in ir_models:\n",
    "#     if ir_path.stem not in ignore_models:\n",
    "#         benchmark_model(ir_path, seconds=15)\n",
    "#         time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd40b99d-54d2-401e-88a2-2876ee1ecfee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
